import google.generativeai as genai
import os
from dotenv import load_dotenv
import time
import re
from tqdm import tqdm
from config import GEMINI_MODEL_NAME, MAX_RETRIES, RETRY_DELAY_MULTIPLIER, API_REQUEST_DELAY, GEMINI_PROMPT

# APIì— í•œ ë²ˆì— ë³´ë‚¼ ìµœëŒ€ í† í° ìˆ˜
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì‘ë‹µ í† í°, ê¸°íƒ€ ì˜¤ë²„í—¤ë“œë¥¼ ê³ ë ¤í•´ì•¼ í•¨
MAX_TOKENS_PER_BATCH = 16000

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
system_prompt = GEMINI_PROMPT

def _get_sentiment_batch(model, batch: list):
    user_prompt = "".join([f"{i + 1}. {text}\n" for i, text in enumerate(batch)])
    response = model.generate_content(user_prompt)
    lines = response.text.strip().split('\n')

    scores = []
    for line in lines:
        match = re.search(r",\s*(-?\d+\.?\d*)$", line)
        if match:
            scores.append(float(match.group(1)))
        else:
            scores.append(0.0)  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¤‘ë¦½(0.0)

    # ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ ì˜ˆì™¸ ë°œìƒì‹œì¼œ ì¬ì²˜ë¦¬ ìœ ë„
    if len(scores) != len(batch):
        raise ValueError(f"Output length mismatch: Expected {len(batch)}, got {len(scores)}")

    return scores


def analyze_descriptions(texts: list) -> list:
    print("\nGemini APIë¡œ ë‰´ìŠ¤ ë³¸ë¬¸ ê°ì„± ì ìˆ˜ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤ (í† í° ê¸°ë°˜ ë°°ì¹˜)...")
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key: raise ValueError("GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    genai.configure(api_key=api_key)

    model = genai.GenerativeModel(GEMINI_MODEL_NAME, system_instruction=system_prompt)

    all_scores = []
    current_index = 0

    with tqdm(total=len(texts), desc="Analyzing Texts") as pbar:
        while current_index < len(texts):
            # --- 1. í† í° ê¸°ë°˜ìœ¼ë¡œ ë™ì  ë°°ì¹˜ ìƒì„± ---
            batch_texts = []
            batch_tokens = 0

            while current_index < len(texts):
                text_to_add = texts[current_index]

                # í˜„ì¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í–ˆì„ ë•Œ í† í° ìˆ˜ë¥¼ ë¯¸ë¦¬ ê³„ì‚°
                # count_tokensëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì „ì²´ í† í° ìˆ˜ë¥¼ ê³„ì‚°
                temp_batch = batch_texts + [text_to_add]
                try:
                    tokens_for_temp_batch = model.count_tokens(temp_batch).total_tokens
                except Exception as e:
                    print(f"âš ï¸ í† í° ê³„ì‚° ì¤‘ ì—ëŸ¬ ë°œìƒ (í•´ë‹¹ í…ìŠ¤íŠ¸ ê±´ë„ˆëœ€): {e}")
                    pbar.update(1)  # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì—…ë°ì´íŠ¸
                    current_index += 1  # ë‹¤ìŒ í…ìŠ¤íŠ¸ë¡œ ì´ë™
                    all_scores.append(0.0)  # ì—ëŸ¬ ë°œìƒ í…ìŠ¤íŠ¸ëŠ” 0.0ìœ¼ë¡œ ì²˜ë¦¬
                    continue

                if tokens_for_temp_batch > MAX_TOKENS_PER_BATCH and batch_texts:
                    # í† í° í•œë„ë¥¼ ì´ˆê³¼í•˜ë©´ í˜„ì¬ ë°°ì¹˜ë¥¼ í™•ì •í•˜ê³  ë£¨í”„ ì¢…ë£Œ
                    break
                else:
                    # í•œë„ ì´ë‚´ì´ë©´ ë°°ì¹˜ì— ì¶”ê°€í•˜ê³  ì¸ë±ìŠ¤ ì¦ê°€
                    batch_texts.append(text_to_add)
                    current_index += 1

            if not batch_texts:
                continue  # ì²˜ë¦¬í•  ë°°ì¹˜ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒìœ¼ë¡œ

            # --- 2. ìƒì„±ëœ ë°°ì¹˜ì— ëŒ€í•´ API í˜¸ì¶œ ë° ì¬ì‹œë„ ---
            attempt = 1
            scores = []
            while attempt <= MAX_RETRIES:
                try:
                    scores = _get_sentiment_batch(model, batch_texts)
                    break  # ì„±ê³µ ì‹œ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
                except Exception as e:
                    print(f"API ì—ëŸ¬ (ë°°ì¹˜ í¬ê¸°: {len(batch_texts)}): {e} (ì¬ì‹œë„ {attempt}/{MAX_RETRIES})")
                    attempt += 1
                    if attempt > MAX_RETRIES:
                        print(f"ğŸš¨ ìµœì¢… ì‹¤íŒ¨. í•´ë‹¹ ë°°ì¹˜ë¥¼ 0.0ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                        scores = [0.0] * len(batch_texts)  # ìµœì¢… ì‹¤íŒ¨ ì‹œ 0.0ìœ¼ë¡œ ì±„ì›€
                    else:
                        time.sleep(API_REQUEST_DELAY * (RETRY_DELAY_MULTIPLIER ** (attempt - 1)))

            all_scores.extend(scores)
            pbar.update(len(batch_texts))
            time.sleep(API_REQUEST_DELAY)

    return all_scores

